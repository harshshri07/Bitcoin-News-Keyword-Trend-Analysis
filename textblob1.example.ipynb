{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin News Keyword Trend Analysis: End-to-End Example\n",
    "\n",
    "This notebook demonstrates a complete application of TextBlob for analyzing keyword trends in Bitcoin news and their correlation with Bitcoin price movements.\n",
    "\n",
    "We'll walk through each step of the workflow:\n",
    "1. Fetch news and price data\n",
    "2. Extract keywords using TextBlob\n",
    "3. Analyze trends and correlations\n",
    "4. Test for causality using Granger tests\n",
    "5. Visualize results\n",
    "6. Generate a dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our utility module containing all the required functions\n",
    "import textblob1_utils as utils\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('dashboard', exist_ok=True)\n",
    "\n",
    "# Configure visualizations\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fetch News and Price Data\n",
    "\n",
    "First, we'll fetch Bitcoin-related news and historical price data. For this example, we'll use sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Bitcoin news (using sample data without API key)\n",
    "news_df = utils.fetch_bitcoin_news(api_key=None, days=30)\n",
    "print(f\"Fetched {len(news_df)} news articles\")\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Bitcoin price data (using sample data)\n",
    "price_df = utils.fetch_bitcoin_prices(days=30, interval='daily')\n",
    "print(f\"Fetched {len(price_df)} days of price data\")\n",
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current Bitcoin price for dashboard\n",
    "current_price = utils.fetch_current_bitcoin_price()\n",
    "print(f\"Current Bitcoin price: ${current_price['price']:.2f} at {current_price['timestamp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Keywords Using TextBlob\n",
    "\n",
    "Now we'll use TextBlob to extract important keywords (noun phrases) from the news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from news articles\n",
    "news_with_keywords = utils.extract_keywords(news_df, min_frequency=1, include_titles=True)\n",
    "\n",
    "# Display example of extracted keywords\n",
    "print(\"Sample of extracted keywords:\")\n",
    "for i, row in news_with_keywords.head(3).iterrows():\n",
    "    print(f\"Article: {row['title']}\")\n",
    "    print(f\"Keywords: {', '.join(row['keywords'][:5]) if len(row['keywords']) > 0 else 'None'}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Analyze Trends and Correlations\n",
    "\n",
    "Next, we'll analyze the trends by counting keyword frequencies, merging with price data, and computing correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trends by merging keyword counts with price data\n",
    "merged_df = utils.analyze_trends(news_with_keywords, price_df, time_window='daily', min_freq=1)\n",
    "\n",
    "# Display the top keywords by frequency\n",
    "print(\"Top 10 keywords by frequency:\")\n",
    "top_keywords = merged_df.drop_duplicates('keyword').sort_values('frequency', ascending=False).head(10)\n",
    "top_keywords[['keyword', 'frequency', 'correlation']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Perform Granger Causality Tests\n",
    "\n",
    "Now we'll perform Granger causality tests to determine if keywords can predict price changes or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Granger causality tests\n",
    "causality_results = utils.run_granger_tests(merged_df, top_n=10, max_lag=3)\n",
    "\n",
    "# Display causality results\n",
    "if causality_results is not None and not causality_results.empty:\n",
    "    print(\"Granger Causality Test Results:\")\n",
    "    causality_results[['keyword', 'correlation', 'k2p_significant', 'p2k_significant']].sort_values(\n",
    "        'correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Results\n",
    "\n",
    "Let's visualize the results with plots showing keyword frequency vs. price and correlation heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot keyword frequency vs. price for the top correlated keyword\n",
    "if not merged_df.empty and len(merged_df['keyword'].unique()) > 0:\n",
    "    top_keyword = top_keywords.iloc[0]['keyword']\n",
    "    print(f\"Plotting frequency vs. price for top keyword: {top_keyword}\")\n",
    "    utils.plot_keyword_vs_price(merged_df, top_keyword, save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of top keywords and their price correlations\n",
    "utils.plot_keyword_price_heatmap(merged_df, top_n=10, save_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate Interactive Dashboard\n",
    "\n",
    "Finally, we'll generate an interactive HTML dashboard summarizing our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate interactive dashboard\n",
    "dashboard_path = utils.generate_dashboard(merged_df, output_path='dashboard/index.html')\n",
    "print(f\"Dashboard generated at: {dashboard_path}\")\n",
    "\n",
    "# Try to open the dashboard in a browser\n",
    "try:\n",
    "    import webbrowser\n",
    "    webbrowser.open(dashboard_path)\n",
    "except:\n",
    "    print(\"Could not automatically open dashboard. Please open the file manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the complete workflow for analyzing Bitcoin news keyword trends using TextBlob:\n",
    "\n",
    "1. **Data Collection**: We fetched Bitcoin news and price data\n",
    "2. **Keyword Extraction**: We used TextBlob to extract meaningful keywords from articles\n",
    "3. **Trend Analysis**: We analyzed frequency trends and correlations with price movements\n",
    "4. **Causality Testing**: We used Granger tests to assess potential causal relationships\n",
    "5. **Visualization**: We created plots showing keyword trends and correlations\n",
    "6. **Dashboard**: We generated an interactive HTML dashboard summarizing our findings\n",
    "\n",
    "The entire process is automated through our utility functions in `textblob1_utils.py`. To use this with real data, simply provide a valid NewsAPI key to the `fetch_bitcoin_news` function."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
